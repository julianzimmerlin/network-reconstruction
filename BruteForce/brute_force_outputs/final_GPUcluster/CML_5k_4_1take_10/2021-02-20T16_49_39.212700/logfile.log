../data/final/cml/timeseries_bull_5k_4_onetake.pickle
../data/final/cml/edges_bull.pickle
SEED: 0
NUM_RUNS: 1
BATCH_SIZE: 100
NUM_DYN_EPOCHS: 10
FORMAT: standard
HIDDEN_SIZE: 128
tensor([[0., 1., 1., 0., 0.],
        [1., 0., 1., 1., 0.],
        [1., 1., 0., 0., 1.],
        [0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0.]])
num samples: 4991
NUM_SAMPLES: 4991
BATCH_SIZE: 100
HIDDEN_SIZE: 128
NUM_DYN_EPOCHS: 10
IS_CONTINUOUS: True
NUM_BATCHES: 50
USE_MAX: False
evaluating: matrix 0, run 0. Loss in Epoch 0: 0.2866211235523224
Loss in Epoch 1: 0.2821744382381439
Loss in Epoch 2: 0.27863577008247375
Loss in Epoch 3: 0.2754162847995758
Loss in Epoch 4: 0.2724151909351349
Loss in Epoch 5: 0.2696654200553894
Loss in Epoch 6: 0.2671535015106201
Loss in Epoch 7: 0.26472026109695435
Loss in Epoch 8: 0.26251041889190674
Loss in Epoch 9: 0.2604619264602661
Mean loss in evaluation epoch: 0.25941818952560425, epochs needed: 10
evaluating: matrix 1, run 0. Loss in Epoch 0: 0.27279213070869446
Loss in Epoch 1: 0.24325622618198395
Loss in Epoch 2: 0.23830123245716095
Loss in Epoch 3: 0.2357795685529709
Loss in Epoch 4: 0.23356778919696808
Loss in Epoch 5: 0.22952358424663544
Loss in Epoch 6: 0.21972937881946564
Loss in Epoch 7: 0.21627593040466309
Loss in Epoch 8: 0.21502774953842163
Loss in Epoch 9: 0.2140129655599594
Mean loss in evaluation epoch: 0.21346358954906464, epochs needed: 10
evaluating: matrix 2, run 0. Loss in Epoch 0: 0.43890562653541565
Loss in Epoch 1: 0.3117225766181946
Loss in Epoch 2: 0.2899489402770996
Loss in Epoch 3: 0.2858724594116211
Loss in Epoch 4: 0.28332504630088806
Loss in Epoch 5: 0.28099238872528076
Loss in Epoch 6: 0.2785256505012512
Loss in Epoch 7: 0.27569326758384705
Loss in Epoch 8: 0.2699742019176483
Loss in Epoch 9: 0.2518072724342346
Mean loss in evaluation epoch: 0.2485167682170868, epochs needed: 10
evaluating: matrix 3, run 0. Loss in Epoch 0: 0.34870779514312744
Loss in Epoch 1: 0.26158297061920166
Loss in Epoch 2: 0.25214213132858276
Loss in Epoch 3: 0.24826213717460632
Loss in Epoch 4: 0.24167384207248688
Loss in Epoch 5: 0.23773814737796783
Loss in Epoch 6: 0.23618189990520477
Loss in Epoch 7: 0.23461498320102692
Loss in Epoch 8: 0.23282814025878906
Loss in Epoch 9: 0.23066571354866028
Mean loss in evaluation epoch: 0.22938545048236847, epochs needed: 10
evaluating: matrix 4, run 0. Loss in Epoch 0: 0.3153303265571594
Loss in Epoch 1: 0.2856256365776062
Loss in Epoch 2: 0.27835747599601746
Loss in Epoch 3: 0.27454063296318054
Loss in Epoch 4: 0.27097174525260925
Loss in Epoch 5: 0.2666266858577728
Loss in Epoch 6: 0.25266551971435547
Loss in Epoch 7: 0.24323786795139313
Loss in Epoch 8: 0.24057285487651825
Loss in Epoch 9: 0.23833881318569183
Mean loss in evaluation epoch: 0.23715518414974213, epochs needed: 10
evaluating: matrix 5, run 0. Loss in Epoch 0: 0.3694024085998535
Loss in Epoch 1: 0.25935161113739014
Loss in Epoch 2: 0.24471049010753632
Loss in Epoch 3: 0.24071383476257324
Loss in Epoch 4: 0.23782257735729218
Loss in Epoch 5: 0.2340536117553711
Loss in Epoch 6: 0.22677768766880035
Loss in Epoch 7: 0.22401346266269684
Loss in Epoch 8: 0.22261226177215576
Loss in Epoch 9: 0.22142012417316437
Mean loss in evaluation epoch: 0.2208300679922104, epochs needed: 10
evaluating: matrix 6, run 0. Loss in Epoch 0: 0.24359813332557678
Loss in Epoch 1: 0.2295418679714203
Loss in Epoch 2: 0.225076362490654
Loss in Epoch 3: 0.21852520108222961
Loss in Epoch 4: 0.20566394925117493
Loss in Epoch 5: 0.20353659987449646
Loss in Epoch 6: 0.2022944986820221
Loss in Epoch 7: 0.2011207789182663
Loss in Epoch 8: 0.1996164321899414
Loss in Epoch 9: 0.19813258945941925
Mean loss in evaluation epoch: 0.19761592149734497, epochs needed: 10
evaluating: matrix 7, run 0. Loss in Epoch 0: 0.2761019468307495
Loss in Epoch 1: 0.25623711943626404
Loss in Epoch 2: 0.25142982602119446
Loss in Epoch 3: 0.24409699440002441
Loss in Epoch 4: 0.2210802584886551
Loss in Epoch 5: 0.21598590910434723
Loss in Epoch 6: 0.2133612334728241
Loss in Epoch 7: 0.2107446938753128
Loss in Epoch 8: 0.20812873542308807
Loss in Epoch 9: 0.20510822534561157
Mean loss in evaluation epoch: 0.20368726551532745, epochs needed: 10
evaluating: matrix 8, run 0. Loss in Epoch 0: 0.24848245084285736
Loss in Epoch 1: 0.23767691850662231
Loss in Epoch 2: 0.23418238759040833
Loss in Epoch 3: 0.23197756707668304
Loss in Epoch 4: 0.22959499061107635
Loss in Epoch 5: 0.22124896943569183
Loss in Epoch 6: 0.20886781811714172
Loss in Epoch 7: 0.20748046040534973
Loss in Epoch 8: 0.20664937794208527
Loss in Epoch 9: 0.20578844845294952
Mean loss in evaluation epoch: 0.20524385571479797, epochs needed: 10
evaluating: matrix 9, run 0. Loss in Epoch 0: 0.3263850212097168
Loss in Epoch 1: 0.25585734844207764
Loss in Epoch 2: 0.24580202996730804
Loss in Epoch 3: 0.2418084591627121
Loss in Epoch 4: 0.23658215999603271
Loss in Epoch 5: 0.2313298135995865
Loss in Epoch 6: 0.22988702356815338
Loss in Epoch 7: 0.22891803085803986
Loss in Epoch 8: 0.22787468135356903
Loss in Epoch 9: 0.22692112624645233
Mean loss in evaluation epoch: 0.2263776659965515, epochs needed: 10
evaluating: matrix 10, run 0. Loss in Epoch 0: 0.29705917835235596
Loss in Epoch 1: 0.24866625666618347
Loss in Epoch 2: 0.24173706769943237
Loss in Epoch 3: 0.23788006603717804
Loss in Epoch 4: 0.23189416527748108
Loss in Epoch 5: 0.22571396827697754
Loss in Epoch 6: 0.22363699972629547
Loss in Epoch 7: 0.22162774205207825
Loss in Epoch 8: 0.2199418544769287
Loss in Epoch 9: 0.21836602687835693
Mean loss in evaluation epoch: 0.21802851557731628, epochs needed: 10
evaluating: matrix 11, run 0. Loss in Epoch 0: 0.252234548330307
Loss in Epoch 1: 0.23078833520412445
Loss in Epoch 2: 0.22345176339149475
Loss in Epoch 3: 0.2150186449289322
Loss in Epoch 4: 0.2133038341999054
Loss in Epoch 5: 0.21229849755764008
Loss in Epoch 6: 0.211256206035614
Loss in Epoch 7: 0.21001368761062622
